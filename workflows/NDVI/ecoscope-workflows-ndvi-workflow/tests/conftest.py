# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details


import functools
import hashlib
import io
import uuid
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Coroutine, Generator, Literal, Iterator
from unittest.mock import patch

import numpy as np
import pytest
import ruamel.yaml
from PIL import Image
from playwright.async_api import async_playwright
from skimage.metrics import structural_similarity as ssim
from syrupy import SnapshotAssertion
from syrupy.extensions.json import JSONSnapshotExtension
from syrupy.extensions.image import PNGImageSnapshotExtension
from syrupy.location import PyTestLocation
from syrupy.terminal import reset
from syrupy.types import SerializedData, SnapshotIndex

from ecoscope_workflows_runner.app import app
from ecoscope_workflows_runner.testing import Case, CaseRunner

ARTIFACTS = Path(__file__).parent.parent
SNAPSHOT_DIRNAME = ARTIFACTS.parent / "__results_snapshots__"
SNAPSHOT_DIFF_OUTPUT_DIRNAME = ARTIFACTS.parent / "__diff_output__"
TEST_CASES_YAML = ARTIFACTS.parent / "test-cases.yaml"
ENTRYPOINT = "pixi run -e default ecoscope-workflows-ndvi-workflow"
MATCHSPEC_OVERRIDE = "ecoscope-workflows-ndvi-workflow"
IO_TASKS_IMPORTABLE_REFERENCES = [
    "ecoscope_workflows_ext_ecoscope.tasks.io.download_roi",
    "ecoscope_workflows_ext_ecoscope.tasks.io.calculate_ndvi_range",
]

yaml = ruamel.yaml.YAML(typ="safe")


def _parse_case(value: str) -> Case:
    all_cases = yaml.load(Path(TEST_CASES_YAML).read_text())
    assert value in all_cases, f"'case_name = {value}' not found in {TEST_CASES_YAML =}"
    return Case(**all_cases[value])


def pytest_addoption(parser: pytest.Parser):
    parser.addoption(
        "--case",
        action="append",
        default=[],
        help=(
            "Specify the test case to run. Must be field names in test-cases.yaml. "
            "Can be specified multiple times."
        ),
    )


def pytest_generate_tests(metafunc: pytest.Metafunc):
    if (
        "success_case" in metafunc.fixturenames
        or "failure_case" in metafunc.fixturenames
    ) and not metafunc.config.getoption("case"):
        raise ValueError("At least one --case must be specified.")

    all_cases = {c: _parse_case(c) for c in metafunc.config.getoption("case")}
    if "success_case" in metafunc.fixturenames:
        success_cases = {k: v for k, v in all_cases.items() if not v.raises}
        metafunc.parametrize(
            "success_case",
            list(success_cases.values()),
            ids=list(success_cases),
            scope="session",
        )
    elif "failure_case" in metafunc.fixturenames:
        failure_cases = {k: v for k, v in all_cases.items() if v.raises}
        metafunc.parametrize(
            "failure_case",
            list(failure_cases.values()),
            ids=list(failure_cases),
            scope="session",
        )


class CustomSnapshotDirnameMixin:
    @classmethod
    def dirname(cls, *, test_location: "PyTestLocation") -> str:
        case_id = next(
            c
            for c in test_location.item.config.getoption("case")
            if c in test_location.item.nodeid
        )
        return SNAPSHOT_DIRNAME.joinpath(case_id).absolute().as_posix()


class CustomJSONSnapshot(CustomSnapshotDirnameMixin, JSONSnapshotExtension):
    @classmethod
    def get_snapshot_name(
        cls, *, test_location: "PyTestLocation", index: "SnapshotIndex"
    ) -> str:
        original_name = JSONSnapshotExtension.get_snapshot_name(
            test_location=test_location, index=index
        )
        test_name = original_name.split("[").pop(0)
        execution_mode = next(
            s for s in original_name.split("-") if s in ["async", "sequential"]
        )
        hasdata = "nodata" if "nodata" in original_name else "data"
        specifier = hasdata + (f"-{execution_mode}" if "failure" in test_name else "")
        return test_name + f"[{specifier}]"


def _png_bytes_to_array(png_bytes: bytes) -> np.ndarray:
    img = Image.open(io.BytesIO(png_bytes))
    return np.array(img)


def _join_png_images(png_bytes1: bytes, png_bytes2: bytes) -> bytes:
    """Join two PNG images horizontally.

    Args:
    png_bytes1 (bytes): Byte string of the first PNG image
    png_bytes2 (bytes): Byte string of the second PNG image

    Returns:
    bytes: A byte string representing the combined PNG image
    """
    # Open images from byte strings
    img1 = Image.open(io.BytesIO(png_bytes1))
    img2 = Image.open(io.BytesIO(png_bytes2))

    # Determine the height of the combined image (using the taller image's height)
    # Calculate total width
    max_height = max(img1.height, img2.height)
    total_width = img1.width + img2.width

    # Create a new image with the combined dimensions
    # Paste the first image on the left and the second on the right
    combined_img = Image.new("RGBA", (total_width, max_height), (0, 0, 0, 0))
    combined_img.paste(img1, (0, (max_height - img1.height) // 2))
    combined_img.paste(img2, (img1.width, (max_height - img2.height) // 2))

    # Save the combined image to a byte stream
    output_stream = io.BytesIO()
    combined_img.save(output_stream, format="PNG")
    output_stream.seek(0)

    return output_stream.getvalue()


class CustomPNGSnapshot(CustomSnapshotDirnameMixin, PNGImageSnapshotExtension):
    @classmethod
    def get_snapshot_name(
        cls, *, test_location: "PyTestLocation", index: "SnapshotIndex"
    ) -> str:
        original_name = PNGImageSnapshotExtension.get_snapshot_name(
            test_location=test_location, index=index
        )
        test_name = original_name.split("[").pop(0)
        widget_name = original_name.split("[").pop(-1).split("]").pop(0)
        return f"{test_name}[{widget_name}]"

    @functools.cache
    def get_structural_similarity(
        self, serialized_data: bytes, snapshot_data: bytes
    ) -> float:
        serialized_arr = _png_bytes_to_array(serialized_data)
        snapshot_arr = _png_bytes_to_array(snapshot_data)
        return ssim(serialized_arr, snapshot_arr, multichannel=True, channel_axis=-1)

    def matches(self, *, serialized_data, snapshot_data):
        similarity = self.get_structural_similarity(serialized_data, snapshot_data)
        return similarity == 1.0

    def diff_lines(
        self, serialized_data: "SerializedData", snapshot_data: "SerializedData"
    ) -> Iterator[str]:
        # TODO: if AbstractSyrupyExtension.diff_lines signature is extended to be passed
        # test_location & index args from SnapshotAssertion, and SnapshotAssertion.get_assert_diff
        # passes those args to the extension.diff_lines call, then we can call self.get_location
        # with those args here and resolve a more human readable name.
        snapshot_data_hash = hashlib.sha256(snapshot_data).hexdigest()[0:7]
        serialized_data_hash = hashlib.sha256(serialized_data).hexdigest()[0:7]
        similarity = self.get_structural_similarity(serialized_data, snapshot_data)
        diff_image_fname = (
            f"{snapshot_data_hash}_{serialized_data_hash}_ssim{similarity}.diff.png"
        )
        diff_image_bytes = _join_png_images(snapshot_data, serialized_data)

        if not SNAPSHOT_DIFF_OUTPUT_DIRNAME.exists():
            SNAPSHOT_DIFF_OUTPUT_DIRNAME.mkdir(parents=True, exist_ok=True)
        for fname, data in [
            (diff_image_fname, diff_image_bytes),
            (f"{snapshot_data_hash}.png", snapshot_data),
            (f"{serialized_data_hash}.png", serialized_data),
        ]:
            SNAPSHOT_DIFF_OUTPUT_DIRNAME.joinpath(fname).write_bytes(data)

        for line in self._SnapshotReporter__diff_lines(str(1.0), str(similarity)):
            yield reset(line)


@pytest.fixture
def snapshot_json(snapshot: SnapshotAssertion) -> SnapshotAssertion:
    return snapshot.use_extension(CustomJSONSnapshot)


@pytest.fixture
def snapshot_png(snapshot: SnapshotAssertion) -> SnapshotAssertion:
    return snapshot.use_extension(CustomPNGSnapshot)


@pytest.fixture(scope="session")
def results_dir(tmp_path_factory: pytest.TempPathFactory) -> Path:
    results_dir = tmp_path_factory.mktemp("results")
    return results_dir


@dataclass
class RunParams:
    api: Literal["app", "cli"]
    execution_mode: Literal["async", "sequential"]
    mock_io: bool = True

    @property
    def subdir_name(self):
        mock_io = "mock-io" if self.mock_io else "no-mock-io"
        return f"{self.api}-{self.execution_mode}-{mock_io}"


@pytest.fixture(
    scope="session",
    params=[
        RunParams(api="app", execution_mode="async"),
        RunParams(api="app", execution_mode="sequential"),
        RunParams(api="cli", execution_mode="async"),
        RunParams(api="cli", execution_mode="sequential"),
    ],
    ids=[
        "app-async-mock-io",
        "app-sequential-mock-io",
        "cli-async-mock-io",
        "cli-sequential-mock-io",
    ],
)
def run_params(request: pytest.FixtureRequest) -> RunParams:
    return request.param


def _run_test_case(
    run_params: RunParams,
    case: Case,
    results_dir: Path,
    matchspec_override: str,
    data_connections_env_vars: dict | None = None,
    no_data: bool | None = None,
) -> Generator[dict, None, None]:
    match no_data:
        case None:
            hasdata = ""
        case True:
            hasdata = "-nodata"
        case False:
            hasdata = "-data"
        case _:
            raise ValueError(f"Unknown no_data value: {no_data}")
    name = case.name.lower().replace(" ", "-") + hasdata
    results_subdir = results_dir / run_params.subdir_name / name / uuid.uuid4().hex
    results_subdir.mkdir(parents=True)
    case_runner = CaseRunner(
        execution_mode=run_params.execution_mode,
        mock_io=run_params.mock_io,
        case=case,
        results_subdir=results_subdir,
    )
    match run_params.api:
        case "app":
            with patch.dict(
                "os.environ",
                {"ECOSCOPE_WORKFLOWS_MATCHSPEC_OVERRIDE": matchspec_override},
            ):
                yield case_runner.run_app(
                    app, data_connections_env_vars=data_connections_env_vars
                )
        case "cli":
            if case.raises:
                pytest.skip("CLI tests do not yet support error handling.")
            yield case_runner.run_cli(ENTRYPOINT)
        case _ as unknown:
            raise ValueError(f"Unknown API: {unknown}")


@pytest.fixture(scope="session")
def matchspec_override() -> str:
    return MATCHSPEC_OVERRIDE


@pytest.fixture(scope="session", params=[True, False], ids=["nodata", "data"])
def no_data(request: pytest.FixtureRequest) -> bool:
    """Fixture to control whether data is null or not."""
    return request.param


@pytest.fixture(scope="session")
def io_tasks_importable_references() -> list[str]:
    """Fixture to provide importable references for all io tasks in this workflow."""
    return IO_TASKS_IMPORTABLE_REFERENCES


@pytest.fixture(scope="session")
def response_json_success(
    run_params: RunParams,
    success_case: Case,
    results_dir: Path,
    matchspec_override: str,
    no_data: bool,
    tmp_path_factory: pytest.TempPathFactory,
    io_tasks_importable_references: list[str],
) -> Generator[dict, None, None]:
    data_connections_env_vars = None
    if no_data:
        import pandas as pd

        mock_io_dir = tmp_path_factory.mktemp("mock-io")
        example_return_path = mock_io_dir.joinpath("empty.parquet")
        pd.DataFrame().to_parquet(example_return_path)
        data_connections_env_vars = {
            f"ECOSCOPE_WORKFLOWS_MOCK_IO__{ref.replace('.', '_').upper()}": example_return_path.as_posix()
            for ref in io_tasks_importable_references
        }
    yield from _run_test_case(
        run_params,
        success_case,
        results_dir,
        matchspec_override,
        data_connections_env_vars,
        no_data,
    )


@pytest.fixture(scope="session")
def response_json_failure(
    run_params: RunParams,
    failure_case: Case,
    results_dir: Path,
    matchspec_override: str,
) -> Generator[dict, None, None]:
    yield from _run_test_case(run_params, failure_case, results_dir, matchspec_override)


def _iframe_widgets_from_response_json(response_json: dict) -> list[dict]:
    first_view = list(response_json["result"]["views"])[0]
    return [
        widget
        for widget in response_json["result"]["views"][first_view]
        if isinstance(widget["data"], str) and widget["data"].endswith(".html")
    ]


async def _take_screenshot(widget: dict) -> tuple[str, bytes]:
    assert widget["widget_type"] in ["map", "graph"]
    async with async_playwright() as p:
        browser = await p.chromium.launch()
        page = await browser.new_page()
        await page.set_viewport_size({"width": 640, "height": 360})
        await page.goto(Path(widget["data"]).as_uri())
        if widget["widget_type"] == "map":
            await page.wait_for_timeout(20_000)
        await page.wait_for_timeout(10_000)
        png_bytes = await page.screenshot(full_page=True, timeout=0)
        return widget["title"], png_bytes


@pytest.fixture(scope="session")
def screenshot_coros(
    response_json_success: dict,
) -> list[Coroutine[Any, Any, tuple[str, bytes]]]:
    iframe_widgets = _iframe_widgets_from_response_json(response_json_success)
    return [_take_screenshot(widget) for widget in iframe_widgets]
