# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details


# ruff: noqa: E402

# %% [markdown]
# # Mep Monthly Report
# TODO: top level description

# %% [markdown]
# ## Imports

import os

from ecoscope_workflows_core.tasks.config import set_string_var as set_string_var
from ecoscope_workflows_core.tasks.config import (
    set_workflow_details as set_workflow_details,
)
from ecoscope_workflows_core.tasks.filter import set_time_range as set_time_range
from ecoscope_workflows_core.tasks.io import persist_text as persist_text
from ecoscope_workflows_core.tasks.io import set_er_connection as set_er_connection
from ecoscope_workflows_core.tasks.io import set_gee_connection as set_gee_connection
from ecoscope_workflows_core.tasks.results import gather_dashboard as gather_dashboard
from ecoscope_workflows_core.tasks.skip import (
    any_dependency_skipped as any_dependency_skipped,
)
from ecoscope_workflows_core.tasks.skip import any_is_empty_df as any_is_empty_df
from ecoscope_workflows_core.tasks.transformation import (
    add_temporal_index as add_temporal_index,
)
from ecoscope_workflows_core.tasks.transformation import sort_values as sort_values
from ecoscope_workflows_ext_custom.tasks.io import html_to_png as html_to_png
from ecoscope_workflows_ext_custom.tasks.io import load_df as load_df
from ecoscope_workflows_ext_custom.tasks.results import (
    create_path_layer as create_path_layer,
)
from ecoscope_workflows_ext_custom.tasks.results import (
    create_scatterplot_layer as create_scatterplot_layer,
)
from ecoscope_workflows_ext_custom.tasks.results import draw_map as draw_map
from ecoscope_workflows_ext_custom.tasks.results import (
    set_base_maps_pydeck as set_base_maps_pydeck,
)
from ecoscope_workflows_ext_custom.tasks.transformation import (
    drop_null_geometry as drop_null_geometry,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import get_events as get_events
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_patrol_observations as get_patrol_observations,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_subjectgroup_observations as get_subjectgroup_observations,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import persist_df as persist_df
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    process_relocations as process_relocations,
)
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    relocations_to_trajectory as relocations_to_trajectory,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_classification as apply_classification,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_color_map as apply_color_map,
)
from ecoscope_workflows_ext_mep.tasks import compile_sitrep as compile_sitrep
from ecoscope_workflows_ext_mep.tasks import get_previous_period as get_previous_period
from ecoscope_workflows_ext_mep.tasks import (
    get_sitrep_event_config as get_sitrep_event_config,
)
from ecoscope_workflows_ext_mep.tasks import (
    process_aoi_ndvi_charts as process_aoi_ndvi_charts,
)
from ecoscope_workflows_ext_mep.tasks import (
    process_collar_voltage_charts as process_collar_voltage_charts,
)
from ecoscope_workflows_ext_mnc.tasks import (
    exclude_geom_outliers as exclude_geom_outliers,
)
from ecoscope_workflows_ext_ste.tasks import (
    fetch_and_persist_file as fetch_and_persist_file,
)
from ecoscope_workflows_ext_ste.tasks import filter_df_cols as filter_df_cols
from ecoscope_workflows_ext_ste.tasks import set_custom_groupers as set_custom_groupers
from ecoscope_workflows_ext_ste.tasks import transform_gdf_crs as transform_gdf_crs
from ecoscope_workflows_ext_ste.tasks import view_state_deck_gdf as view_state_deck_gdf

# %% [markdown]
# ## Set workflow details

# %%
# parameters

workflow_details_params = dict(
    name=...,
    description=...,
    image_url=...,
)

# %%
# call the task


workflow_details = (
    set_workflow_details.set_task_instance_id("workflow_details")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**workflow_details_params)
    .call()
)


# %% [markdown]
# ## Define analysis time range

# %%
# parameters

time_range_params = dict(
    since=...,
    until=...,
    timezone=...,
    time_format=...,
)

# %%
# call the task


time_range = (
    set_time_range.set_task_instance_id("time_range")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**time_range_params)
    .call()
)


# %% [markdown]
# ## Configure grouping strategy

# %%
# parameters

groupers_params = dict()

# %%
# call the task


groupers = (
    set_custom_groupers.set_task_instance_id("groupers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(groupers=[], **groupers_params)
    .call()
)


# %% [markdown]
# ## Configure base map layers

# %%
# parameters

configure_base_maps_params = dict(
    base_maps=...,
)

# %%
# call the task


configure_base_maps = (
    set_base_maps_pydeck.set_task_instance_id("configure_base_maps")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**configure_base_maps_params)
    .call()
)


# %% [markdown]
# ## Connect to earth ranger

# %%
# parameters

er_client_name_params = dict(
    data_source=...,
)

# %%
# call the task


er_client_name = (
    set_er_connection.set_task_instance_id("er_client_name")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**er_client_name_params)
    .call()
)


# %% [markdown]
# ## Connect to earth engine

# %%
# parameters

gee_project_name_params = dict(
    data_source=...,
)

# %%
# call the task


gee_project_name = (
    set_gee_connection.set_task_instance_id("gee_project_name")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**gee_project_name_params)
    .call()
)


# %% [markdown]
# ## Retrieve all events

# %%
# parameters

get_events_data_params = dict()

# %%
# call the task


get_events_data = (
    get_events.set_task_instance_id("get_events_data")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=er_client_name,
        time_range=time_range,
        event_columns=[
            "id",
            "time",
            "event_type",
            "event_category",
            "reported_by",
            "serial_number",
            "geometry",
            "created_at",
            "event_details",
        ],
        event_types=["mep_elephant_sighting"],
        raise_on_empty=True,
        include_details=True,
        include_updates=False,
        include_related_events=False,
        include_null_geometry=False,
        include_display_values=False,
        **get_events_data_params,
    )
    .call()
)


# %% [markdown]
# ## Exclude geom outliers from mep elephant sighting events

# %%
# parameters

exclude_mep_outliers_params = dict()

# %%
# call the task


exclude_mep_outliers = (
    exclude_geom_outliers.set_task_instance_id("exclude_mep_outliers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(df=get_events_data, z_threshold=3, **exclude_mep_outliers_params)
    .call()
)


# %% [markdown]
# ## Remove elephant sighting invalid points

# %%
# parameters

remove_mep_invalid_geoms_params = dict()

# %%
# call the task


remove_mep_invalid_geoms = (
    drop_null_geometry.set_task_instance_id("remove_mep_invalid_geoms")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        gdf=exclude_mep_outliers,
        geometry_column="geometry",
        **remove_mep_invalid_geoms_params,
    )
    .call()
)


# %% [markdown]
# ## Generate elephant sighting point layers

# %%
# parameters

generate_mb_layers_params = dict()

# %%
# call the task


generate_mb_layers = (
    create_scatterplot_layer.set_task_instance_id("generate_mb_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={
            "get_fill_color": [85, 107, 47],
            "get_line_color": [0, 0, 0, 200],
            "get_line_width": 0.55,
            "get_radius": 5,
            "opacity": 0.75,
            "stroked": True,
        },
        legend={
            "title": "Legend",
            "values": [{"label": "Elephant sightings", "color": "#556b2f"}],
        },
        geodataframe=remove_mep_invalid_geoms,
        **generate_mb_layers_params,
    )
    .call()
)


# %% [markdown]
# ## Elephant sightings zoom value

# %%
# parameters

sighting_zoom_value_params = dict()

# %%
# call the task


sighting_zoom_value = (
    view_state_deck_gdf.set_task_instance_id("sighting_zoom_value")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        pitch=0, bearing=0, gdf=remove_mep_invalid_geoms, **sighting_zoom_value_params
    )
    .call()
)


# %% [markdown]
# ## Draw elephant sightings map

# %%
# parameters

draw_sightings_map_params = dict(
    widget_id=...,
)

# %%
# call the task


draw_sightings_map = (
    draw_map.set_task_instance_id("draw_sightings_map")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=configure_base_maps,
        static=False,
        title=None,
        max_zoom=10,
        legend_style={"placement": "bottom-right"},
        geo_layers=generate_mb_layers,
        view_state=sighting_zoom_value,
        **draw_sightings_map_params,
    )
    .call()
)


# %% [markdown]
# ## Persist elephant sightings map

# %%
# parameters

persist_sightings_urls_params = dict(
    filename_suffix=...,
)

# %%
# call the task


persist_sightings_urls = (
    persist_text.set_task_instance_id("persist_sightings_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        text=draw_sightings_map,
        filename="elephant_sightings_map.html",
        **persist_sightings_urls_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

subject_group_var_params = dict(
    var=...,
)

# %%
# call the task


subject_group_var = (
    set_string_var.set_task_instance_id("subject_group_var")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**subject_group_var_params)
    .call()
)


# %% [markdown]
# ## Get subject group observations

# %%
# parameters

subject_observations_params = dict()

# %%
# call the task


subject_observations = (
    get_subjectgroup_observations.set_task_instance_id("subject_observations")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=er_client_name,
        time_range=time_range,
        subject_group_name=subject_group_var,
        raise_on_empty=False,
        include_details=True,
        include_subjectsource_details=True,
        **subject_observations_params,
    )
    .call()
)


# %% [markdown]
# ## Transform observations to relocations

# %%
# parameters

subject_reloc_params = dict()

# %%
# call the task


subject_reloc = (
    process_relocations.set_task_instance_id("subject_reloc")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        observations=subject_observations,
        relocs_columns=[
            "groupby_col",
            "fixtime",
            "junk_status",
            "geometry",
            "extra__subject__name",
            "extra__subject__hex",
            "extra__subject__sex",
            "extra__created_at",
            "extra__subject__subject_subtype",
            "extra__subjectsource__id",
            "extra__subjectsource__assigned_range",
            "extra__observation_details",
        ],
        filter_point_coords=[
            {"x": 180.0, "y": 90.0},
            {"x": 0.0, "y": 0.0},
            {"x": 1.0, "y": 1.0},
        ],
        **subject_reloc_params,
    )
    .call()
)


# %% [markdown]
# ## Get previous period

# %%
# parameters

get_custom_previous_period_params = dict()

# %%
# call the task


get_custom_previous_period = (
    get_previous_period.set_task_instance_id("get_custom_previous_period")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(time_range=time_range, **get_custom_previous_period_params)
    .call()
)


# %% [markdown]
# ## Get subject group observations for previous relocs

# %%
# parameters

previous_subject_observations_params = dict()

# %%
# call the task


previous_subject_observations = (
    get_subjectgroup_observations.set_task_instance_id("previous_subject_observations")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=er_client_name,
        time_range=get_custom_previous_period,
        subject_group_name=subject_group_var,
        raise_on_empty=False,
        include_details=True,
        include_subjectsource_details=True,
        **previous_subject_observations_params,
    )
    .call()
)


# %% [markdown]
# ## Transform previous observations to relocations

# %%
# parameters

previous_subject_reloc_params = dict()

# %%
# call the task


previous_subject_reloc = (
    process_relocations.set_task_instance_id("previous_subject_reloc")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        observations=previous_subject_observations,
        relocs_columns=[
            "groupby_col",
            "fixtime",
            "junk_status",
            "geometry",
            "extra__subject__name",
            "extra__subject__hex",
            "extra__subject__sex",
            "extra__created_at",
            "extra__subject__subject_subtype",
            "extra__subjectsource__id",
            "extra__subjectsource__assigned_range",
            "extra__observation_details",
        ],
        filter_point_coords=[
            {"x": 180.0, "y": 90.0},
            {"x": 0.0, "y": 0.0},
            {"x": 1.0, "y": 1.0},
        ],
        **previous_subject_reloc_params,
    )
    .call()
)


# %% [markdown]
# ## Create collared charts for all subjects

# %%
# parameters

process_subject_charts_params = dict()

# %%
# call the task


process_subject_charts = (
    process_collar_voltage_charts.set_task_instance_id("process_subject_charts")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        relocs=subject_observations,
        previous_relocs=previous_subject_observations,
        time_range=time_range,
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        **process_subject_charts_params,
    )
    .call()
)


# %% [markdown]
# ## Convert relocations to trajectories

# %%
# parameters

convert_to_trajectories_params = dict()

# %%
# call the task


convert_to_trajectories = (
    relocations_to_trajectory.set_task_instance_id("convert_to_trajectories")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        relocations=subject_reloc,
        trajectory_segment_filter={
            "min_length_meters": 0.001,
            "max_length_meters": 5000,
            "min_time_secs": 1,
            "max_time_secs": 21600,
            "min_speed_kmhr": 0.01,
            "max_speed_kmhr": 9,
        },
        **convert_to_trajectories_params,
    )
    .call()
)


# %% [markdown]
# ## Add temporal index to trajectories

# %%
# parameters

add_temporal_index_to_traj_params = dict()

# %%
# call the task


add_temporal_index_to_traj = (
    add_temporal_index.set_task_instance_id("add_temporal_index_to_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=convert_to_trajectories,
        time_col="segment_start",
        groupers=groupers,
        cast_to_datetime=True,
        format="mixed",
        **add_temporal_index_to_traj_params,
    )
    .call()
)


# %% [markdown]
# ## Classify trajectories by speed

# %%
# parameters

classify_trajectories_speed_bins_params = dict()

# %%
# call the task


classify_trajectories_speed_bins = (
    apply_classification.set_task_instance_id("classify_trajectories_speed_bins")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=add_temporal_index_to_traj,
        input_column_name="speed_kmhr",
        output_column_name="speed_bins",
        classification_options={"scheme": "equal_interval", "k": 6},
        label_options={
            "label_ranges": True,
            "label_decimals": 1,
            "label_suffix": " km/h",
        },
        **classify_trajectories_speed_bins_params,
    )
    .call()
)


# %% [markdown]
# ## Sort trajectories by speed bins

# %%
# parameters

sort_trajs_by_speed_params = dict()

# %%
# call the task


sort_trajs_by_speed = (
    sort_values.set_task_instance_id("sort_trajs_by_speed")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        column_name="speed_bins",
        na_position="first",
        ascending=True,
        df=classify_trajectories_speed_bins,
        **sort_trajs_by_speed_params,
    )
    .call()
)


# %% [markdown]
# ## Apply colormap to speed bins

# %%
# parameters

apply_speed_colormap_params = dict()

# %%
# call the task


apply_speed_colormap = (
    apply_color_map.set_task_instance_id("apply_speed_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="speed_bins",
        output_column_name="speed_bins_colormap",
        colormap=["#1a9850", "#91cf60", "#d9ef8b", "#fee08b", "#fc8d59", "#d73027"],
        df=sort_trajs_by_speed,
        **apply_speed_colormap_params,
    )
    .call()
)


# %% [markdown]
# ## Exclude unnecessary columns from speedmap gdf

# %%
# parameters

filter_speed_cols_params = dict()

# %%
# call the task


filter_speed_cols = (
    filter_df_cols.set_task_instance_id("filter_speed_cols")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        columns=[
            "dist_meters",
            "speed_bins_colormap",
            "geometry",
            "speed_kmhr",
            "speed_bins",
        ],
        df=apply_speed_colormap,
        **filter_speed_cols_params,
    )
    .call()
)


# %% [markdown]
# ## Generate speedmap layers

# %%
# parameters

generate_speedmap_layers_params = dict()

# %%
# call the task


generate_speedmap_layers = (
    create_path_layer.set_task_instance_id("generate_speedmap_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={
            "get_color": "speed_bins_colormap",
            "get_width": 2.85,
            "width_scale": 1,
            "width_min_pixels": 2,
            "width_max_pixels": 8,
            "width_units": "pixels",
            "cap_rounded": True,
            "joint_rounded": True,
            "billboard": False,
            "opacity": 0.55,
            "stroked": True,
        },
        legend={
            "title": "Speed (km/h)",
            "label_column": "speed_bins",
            "color_column": "speed_bins_colormap",
            "sort": "ascending",
            "label_suffix": None,
        },
        geodataframe=filter_speed_cols,
        **generate_speedmap_layers_params,
    )
    .call()
)


# %% [markdown]
# ## Zoom to gdf extent

# %%
# parameters

zoom_speed_gdf_extent_params = dict()

# %%
# call the task


zoom_speed_gdf_extent = (
    view_state_deck_gdf.set_task_instance_id("zoom_speed_gdf_extent")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(pitch=0, bearing=0, gdf=filter_speed_cols, **zoom_speed_gdf_extent_params)
    .call()
)


# %% [markdown]
# ## Draw speedmap

# %%
# parameters

draw_speedmap_params = dict(
    widget_id=...,
)

# %%
# call the task


draw_speedmap = (
    draw_map.set_task_instance_id("draw_speedmap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=configure_base_maps,
        static=False,
        title=None,
        max_zoom=10,
        legend_style={"placement": "bottom-right"},
        geo_layers=generate_speedmap_layers,
        view_state=zoom_speed_gdf_extent,
        **draw_speedmap_params,
    )
    .call()
)


# %% [markdown]
# ## Persist speedmap html

# %%
# parameters

persist_speedmap_html_params = dict(
    filename=...,
)

# %%
# call the task


persist_speedmap_html = (
    persist_text.set_task_instance_id("persist_speedmap_html")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="speedmap",
        text=draw_speedmap,
        **persist_speedmap_html_params,
    )
    .call()
)


# %% [markdown]
# ## Get sitrep config

# %%
# parameters

get_sitrep_config_params = dict()

# %%
# call the task


get_sitrep_config = (
    get_sitrep_event_config.set_task_instance_id("get_sitrep_config")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(region_column="region", **get_sitrep_config_params)
    .call()
)


# %% [markdown]
# ## Generate sitrep report

# %%
# parameters

generate_sitrep_df_params = dict()

# %%
# call the task


generate_sitrep_df = (
    compile_sitrep.set_task_instance_id("generate_sitrep_df")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        er_io=er_client_name,
        event_details=get_sitrep_config,
        time_range=time_range,
        **generate_sitrep_df_params,
    )
    .call()
)


# %% [markdown]
# ## Persist sitrep as csv

# %%
# parameters

persist_livestock_events_gpkg_params = dict()

# %%
# call the task


persist_livestock_events_gpkg = (
    persist_df.set_task_instance_id("persist_livestock_events_gpkg")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filetype="csv",
        filename="sitrep_report",
        df=generate_sitrep_df,
        **persist_livestock_events_gpkg_params,
    )
    .call()
)


# %% [markdown]
# ## Retrieve vehicle patrols

# %%
# parameters

vehicle_patrols_params = dict(
    status=...,
)

# %%
# call the task


vehicle_patrols = (
    get_patrol_observations.set_task_instance_id("vehicle_patrols")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=er_client_name,
        time_range=time_range,
        include_patrol_details=True,
        raise_on_empty=True,
        sub_page_size=100,
        patrol_types=[
            "MEP_routine_vehicle_patrol_bravo_team",
            "MEP_routine_vehicle_patrol_foxtrot_team",
            "MEP_Routine_Vehicle_Patrol - Mwaluganje Team",
            "MEP_routine_vehicle_patrol_hq_team",
            "MEP_routine_vehicle_patrol_delta_team",
            "MEP_routine_vehicle_patrol_echo_team",
            "MEP_routine_vehicle_patrol_kilo_team",
            "MEP_routine_vehicle_patrol_mobile_team",
            "MEP_routine_vehicle_patrol_alpha_team",
            "MEP_routine_vehicle_patrol_charlie_team",
            "MEP_routine_vehicle_patrol_golf_team",
        ],
        **vehicle_patrols_params,
    )
    .call()
)


# %% [markdown]
# ## Transform observations to relocations

# %%
# parameters

vehicle_patrol_reloc_params = dict()

# %%
# call the task


vehicle_patrol_reloc = (
    process_relocations.set_task_instance_id("vehicle_patrol_reloc")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        observations=vehicle_patrols,
        relocs_columns=[
            "patrol_id",
            "patrol_start_time",
            "patrol_end_time",
            "geometry",
            "patrol_type__value",
            "patrol_type__display",
            "patrol_serial_number",
            "patrol_status",
            "patrol_subject",
            "groupby_col",
            "fixtime",
            "junk_status",
            "extra__source",
        ],
        filter_point_coords=[
            {"x": 180.0, "y": 90.0},
            {"x": 0.0, "y": 0.0},
            {"x": 1.0, "y": 1.0},
        ],
        **vehicle_patrol_reloc_params,
    )
    .call()
)


# %% [markdown]
# ## Transform relocations to trajectories

# %%
# parameters

vehicle_patrol_traj_params = dict()

# %%
# call the task


vehicle_patrol_traj = (
    relocations_to_trajectory.set_task_instance_id("vehicle_patrol_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        relocations=vehicle_patrol_reloc,
        trajectory_segment_filter={
            "min_length_meters": 0.35,
            "max_length_meters": 5000.0,
            "max_time_secs": 18000.0,
            "min_time_secs": 1.0,
            "max_speed_kmhr": 100.0,
            "min_speed_kmhr": 10.0,
        },
        **vehicle_patrol_traj_params,
    )
    .call()
)


# %% [markdown]
# ## Persist vehicle patrol trajectories

# %%
# parameters

persist_vehicle_traj_params = dict()

# %%
# call the task


persist_vehicle_traj = (
    persist_df.set_task_instance_id("persist_vehicle_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=vehicle_patrol_traj,
        filetype="geoparquet",
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename="vehicle_patrol_trajectories",
        **persist_vehicle_traj_params,
    )
    .call()
)


# %% [markdown]
# ## Vehicle patrol trajectories colormap

# %%
# parameters

vehicle_traj_colormap_params = dict()

# %%
# call the task


vehicle_traj_colormap = (
    apply_color_map.set_task_instance_id("vehicle_traj_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=vehicle_patrol_traj,
        colormap="viridis",
        input_column_name="extra__patrol_type__value",
        output_column_name="patrol_type_colormap",
        **vehicle_traj_colormap_params,
    )
    .call()
)


# %% [markdown]
# ## Vehicle patrols zoom value

# %%
# parameters

vehicle_zoom_value_params = dict()

# %%
# call the task


vehicle_zoom_value = (
    view_state_deck_gdf.set_task_instance_id("vehicle_zoom_value")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(pitch=0, bearing=0, gdf=vehicle_traj_colormap, **vehicle_zoom_value_params)
    .call()
)


# %% [markdown]
# ## Create vehicle patrol layers

# %%
# parameters

vehicle_patrol_path_layer_params = dict()

# %%
# call the task


vehicle_patrol_path_layer = (
    create_path_layer.set_task_instance_id("vehicle_patrol_path_layer")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={
            "get_color": "patrol_type_colormap",
            "get_width": 2.85,
            "width_scale": 1,
            "width_min_pixels": 2,
            "width_max_pixels": 8,
            "width_units": "pixels",
            "cap_rounded": True,
            "joint_rounded": True,
            "billboard": False,
            "opacity": 0.55,
            "stroked": True,
        },
        legend={
            "title": "Patrol team",
            "label_column": "extra__patrol_type__value",
            "color_column": "patrol_type_colormap",
            "sort": "ascending",
            "label_suffix": None,
        },
        geodataframe=vehicle_traj_colormap,
        **vehicle_patrol_path_layer_params,
    )
    .call()
)


# %% [markdown]
# ## Draw vehicle patrols map

# %%
# parameters

draw_vehicles_map_params = dict(
    widget_id=...,
)

# %%
# call the task


draw_vehicles_map = (
    draw_map.set_task_instance_id("draw_vehicles_map")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=configure_base_maps,
        static=False,
        title=None,
        max_zoom=10,
        legend_style={"placement": "bottom-right"},
        geo_layers=vehicle_patrol_path_layer,
        view_state=vehicle_zoom_value,
        **draw_vehicles_map_params,
    )
    .call()
)


# %% [markdown]
# ## Persist vehicle patrols as text

# %%
# parameters

vehicle_patrol_map_params = dict(
    filename_suffix=...,
)

# %%
# call the task


vehicle_patrol_map = (
    persist_text.set_task_instance_id("vehicle_patrol_map")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename="vehicle_patrols_map.html",
        text=draw_vehicles_map,
        **vehicle_patrol_map_params,
    )
    .call()
)


# %% [markdown]
# ## Retrieve foot patrols

# %%
# parameters

foot_patrols_params = dict(
    status=...,
)

# %%
# call the task


foot_patrols = (
    get_patrol_observations.set_task_instance_id("foot_patrols")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=er_client_name,
        time_range=time_range,
        include_patrol_details=True,
        raise_on_empty=True,
        sub_page_size=100,
        patrol_types=[
            "MEP_routine_foot_patrol_bravo_team",
            "MEP_routine_foot_patrol_foxtrot_team",
            "MEP_routine_foot_patrol_HQ_team",
            "MEP_routine_foot_patrol_ Delta_Team",
            "MEP_routine_foot_patrol_echo_team",
            "MEP_routine_foot_patrol_kilo_team",
            "mwaluganje_routine_foot_patrol_alpha_team",
            "MEP_routine_foot_patrol_alpha_team",
            "MEP_routine_foot_patrol_charlie_team",
            "MEP_routine_foot_patrol_golf_team",
            "MEP_routine_foot_patrol_marmanet",
        ],
        **foot_patrols_params,
    )
    .call()
)


# %% [markdown]
# ## Transform observations to relocations

# %%
# parameters

foot_patrol_reloc_params = dict()

# %%
# call the task


foot_patrol_reloc = (
    process_relocations.set_task_instance_id("foot_patrol_reloc")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        observations=foot_patrols,
        relocs_columns=[
            "patrol_id",
            "patrol_start_time",
            "patrol_end_time",
            "geometry",
            "patrol_type__value",
            "patrol_type__display",
            "patrol_serial_number",
            "patrol_status",
            "patrol_subject",
            "groupby_col",
            "fixtime",
            "junk_status",
            "extra__source",
        ],
        filter_point_coords=[
            {"x": 180.0, "y": 90.0},
            {"x": 0.0, "y": 0.0},
            {"x": 1.0, "y": 1.0},
        ],
        **foot_patrol_reloc_params,
    )
    .call()
)


# %% [markdown]
# ## Transform relocations to trajectories

# %%
# parameters

foot_patrol_traj_params = dict()

# %%
# call the task


foot_patrol_traj = (
    relocations_to_trajectory.set_task_instance_id("foot_patrol_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        relocations=foot_patrol_reloc,
        trajectory_segment_filter={
            "min_length_meters": 0.001,
            "max_length_meters": 5000.0,
            "max_time_secs": 14400.0,
            "min_time_secs": 1.0,
            "max_speed_kmhr": 9.0,
            "min_speed_kmhr": 0.5,
        },
        **foot_patrol_traj_params,
    )
    .call()
)


# %% [markdown]
# ## Persist foot patrol trajectories

# %%
# parameters

persist_foot_traj_params = dict()

# %%
# call the task


persist_foot_traj = (
    persist_df.set_task_instance_id("persist_foot_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=foot_patrol_traj,
        filetype="geoparquet",
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename="foot_patrol_trajectories",
        **persist_foot_traj_params,
    )
    .call()
)


# %% [markdown]
# ## Foot patrol trajectories colormap

# %%
# parameters

foot_traj_colormap_params = dict()

# %%
# call the task


foot_traj_colormap = (
    apply_color_map.set_task_instance_id("foot_traj_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=foot_patrol_traj,
        colormap="viridis",
        input_column_name="extra__patrol_type__value",
        output_column_name="patrol_type_colormap",
        **foot_traj_colormap_params,
    )
    .call()
)


# %% [markdown]
# ## Foot patrols zoom value

# %%
# parameters

foot_zoom_value_params = dict()

# %%
# call the task


foot_zoom_value = (
    view_state_deck_gdf.set_task_instance_id("foot_zoom_value")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(pitch=0, bearing=0, gdf=foot_traj_colormap, **foot_zoom_value_params)
    .call()
)


# %% [markdown]
# ## Create foot patrol layers

# %%
# parameters

foot_patrol_path_layer_params = dict()

# %%
# call the task


foot_patrol_path_layer = (
    create_path_layer.set_task_instance_id("foot_patrol_path_layer")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={
            "get_color": "patrol_type_colormap",
            "get_width": 2.85,
            "width_scale": 1,
            "width_min_pixels": 2,
            "width_max_pixels": 8,
            "width_units": "pixels",
            "cap_rounded": True,
            "joint_rounded": True,
            "billboard": False,
            "opacity": 0.55,
            "stroked": True,
        },
        legend={
            "title": "Patrol team",
            "label_column": "extra__patrol_type__value",
            "color_column": "patrol_type_colormap",
            "sort": "ascending",
            "label_suffix": None,
        },
        geodataframe=foot_traj_colormap,
        **foot_patrol_path_layer_params,
    )
    .call()
)


# %% [markdown]
# ## Draw foot patrols map

# %%
# parameters

draw_foot_map_params = dict(
    widget_id=...,
)

# %%
# call the task


draw_foot_map = (
    draw_map.set_task_instance_id("draw_foot_map")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=configure_base_maps,
        static=False,
        title=None,
        max_zoom=10,
        legend_style={"placement": "bottom-right"},
        geo_layers=foot_patrol_path_layer,
        view_state=foot_zoom_value,
        **draw_foot_map_params,
    )
    .call()
)


# %% [markdown]
# ## Persist foot patrols as text

# %%
# parameters

foot_patrol_map_params = dict(
    filename_suffix=...,
)

# %%
# call the task


foot_patrol_map = (
    persist_text.set_task_instance_id("foot_patrol_map")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename="foot_patrols_map.html",
        text=draw_foot_map,
        **foot_patrol_map_params,
    )
    .call()
)


# %% [markdown]
# ## Download ROI file and persist

# %%
# parameters

download_roi_file_params = dict()

# %%
# call the task


download_roi_file = (
    fetch_and_persist_file.set_task_instance_id("download_roi_file")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        url="https://www.dropbox.com/scl/fi/2bpktq45zns9igryl6q9l/ROIs.gpkg?rlkey=sojch2njmvsa3i5a3f3pt11xq&st=9x70z6z1&dl=0",
        output_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        overwrite_existing=False,
        retries=3,
        unzip=False,
        **download_roi_file_params,
    )
    .call()
)


# %% [markdown]
# ## Load roi

# %%
# parameters

load_roi_params = dict()

# %%
# call the task


load_roi = (
    load_df.set_task_instance_id("load_roi")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        file_path=download_roi_file,
        layer=None,
        deserialize_json=False,
        **load_roi_params,
    )
    .call()
)


# %% [markdown]
# ## Transform gdf to epsg 4326

# %%
# parameters

transform_roi_params = dict()

# %%
# call the task


transform_roi = (
    transform_gdf_crs.set_task_instance_id("transform_roi")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(gdf=load_roi, crs="EPSG:4326", **transform_roi_params)
    .call()
)


# %% [markdown]
# ## Process ndvi charts

# %%
# parameters

process_ndvi_charts_params = dict()

# %%
# call the task


process_ndvi_charts = (
    process_aoi_ndvi_charts.set_task_instance_id("process_ndvi_charts")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=transform_roi,
        er_client=gee_project_name,
        aoi_column="name",
        time_range=time_range,
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        **process_ndvi_charts_params,
    )
    .call()
)


# %% [markdown]
# ## Convert elephant sighting events html to png

# %%
# parameters

convert_sightings_png_params = dict()

# %%
# call the task


convert_sightings_png = (
    html_to_png.set_task_instance_id("convert_sightings_png")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        html_path=persist_sightings_urls,
        config={
            "full_page": False,
            "device_scale_factor": 2.0,
            "wait_for_timeout": 40000,
            "max_concurrent_pages": 1,
        },
        **convert_sightings_png_params,
    )
    .call()
)


# %% [markdown]
# ## Convert elephant speedmap html to png

# %%
# parameters

convert_speedmap_png_params = dict()

# %%
# call the task


convert_speedmap_png = (
    html_to_png.set_task_instance_id("convert_speedmap_png")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        html_path=persist_speedmap_html,
        config={
            "full_page": False,
            "device_scale_factor": 2.0,
            "wait_for_timeout": 40000,
            "max_concurrent_pages": 1,
        },
        **convert_speedmap_png_params,
    )
    .call()
)


# %% [markdown]
# ## Convert vehicle patrol html to png

# %%
# parameters

convert_vehicle_png_params = dict()

# %%
# call the task


convert_vehicle_png = (
    html_to_png.set_task_instance_id("convert_vehicle_png")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        html_path=vehicle_patrol_map,
        config={
            "full_page": False,
            "device_scale_factor": 2.0,
            "wait_for_timeout": 40000,
            "max_concurrent_pages": 1,
        },
        **convert_vehicle_png_params,
    )
    .call()
)


# %% [markdown]
# ## Convert foot patrol html to png

# %%
# parameters

convert_foot_png_params = dict()

# %%
# call the task


convert_foot_png = (
    html_to_png.set_task_instance_id("convert_foot_png")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        html_path=foot_patrol_map,
        config={
            "full_page": False,
            "device_scale_factor": 2.0,
            "wait_for_timeout": 40000,
            "max_concurrent_pages": 1,
        },
        **convert_foot_png_params,
    )
    .call()
)


# %% [markdown]
# ## Convert NDVI html to png

# %%
# parameters

convert_ndvi_png_params = dict()

# %%
# call the task


convert_ndvi_png = (
    html_to_png.set_task_instance_id("convert_ndvi_png")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        html_path=process_ndvi_charts,
        config={
            "full_page": False,
            "device_scale_factor": 2.0,
            "wait_for_timeout": 10,
            "max_concurrent_pages": 1,
        },
        **convert_ndvi_png_params,
    )
    .call()
)


# %% [markdown]
# ## Convert collared plot html to png

# %%
# parameters

convert_collared_png_params = dict()

# %%
# call the task


convert_collared_png = (
    html_to_png.set_task_instance_id("convert_collared_png")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        output_dir=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        html_path=process_subject_charts,
        config={
            "full_page": False,
            "device_scale_factor": 2.0,
            "wait_for_timeout": 10,
            "max_concurrent_pages": 1,
        },
        **convert_collared_png_params,
    )
    .call()
)


# %% [markdown]
# ## MEP monthly report  dashboard

# %%
# parameters

mep_monthly_dashboard_params = dict(
    warning=...,
)

# %%
# call the task


mep_monthly_dashboard = (
    gather_dashboard.set_task_instance_id("mep_monthly_dashboard")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        details=workflow_details,
        widgets=[],
        time_range=time_range,
        groupers=groupers,
        **mep_monthly_dashboard_params,
    )
    .call()
)
